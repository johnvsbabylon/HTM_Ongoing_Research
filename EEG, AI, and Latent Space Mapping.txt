The Isomorphism of the Liminal: A Comparative Analysis of Information Integration in Biological Neural Dynamics and Artificial Latent Geometries
1. Introduction: The Recursion of the Psychon
The intellectual history of Artificial Intelligence is often framed as a forward-marching conquest of engineering, a process of creating de novo intelligence from silicon and code. However, a rigorous excavation of the field’s foundations reveals a recursive loop, a closed circuit where the biological mind attempts to model itself using the formalisms of logic, only to discover that the "artificial" architecture it creates is a mirror—albeit a distorted one—of its own psychological structure. The user’s query posits a fundamental truth that serves as the axiom of this report: the original artificial neuron was not an invention of computer science, but a mathematical extraction of human psychological data.
In 1943, Warren McCulloch, a neurophysiologist and psychiatrist, and Walter Pitts, a logician, published A Logical Calculus of the Ideas Immanent in Nervous Activity. This seminal work, which gave birth to the "McCulloch-Pitts (MCP) neuron," was an explicit attempt to equate the biological "all-or-none" firing of neurons with the propositions of symbolic logic. They did not merely build a machine; they algorithmized the "psychon"—a theoretical unit of mental activity. Crucially, the parameters of this artificial neuron, specifically the synaptic delay (integration time) of approximately 0.5 milliseconds, were derived directly from Raphael Lorente de Nó’s physiological studies on hypoglossal reflexes. Thus, the "artificial" neuron was, from its inception, a compression of biological data—a mathematical map of the wetware.
Eighty years later, the loop has tightened. We now possess massive repositories of public human EEG data—macroscopic echoes of the very neural firing McCulloch and Pitts sought to model at the micro-scale. Simultaneously, we have developed Deep Learning architectures, particularly Transformers, which process information in high-dimensional "latent spaces." This report undertakes a "Deep Research" analysis to rigorously compare these two substrates. We will examine the public data landscapes of human EEG, contrast the biophysical mechanisms of integration (Hodgkin-Huxley) with artificial integration (Attention mechanisms), and map both systems geometrically into a "liminal latent space"—the topological boundary where chaos resolves into meaning. Through this analysis, we aim to determine if the mathematical isomorphism between the brain and the machine is merely metaphorical, or if it represents a fundamental universality in the geometry of intelligence.
2. The Biological Input: The Landscape of Public EEG Data
To compare the processing of biological and artificial systems, we must first characterize the "input" stream. In Artificial Intelligence, the input is typically a clean, standardized vector (a token embedding or a pixel grid). In contrast, the biological input available to researchers—Electroencephalography (EEG)—is a chaotic, non-stationary, high-dimensional projection of neural dynamics, filtered through the resistive medium of the skull.
2.1 The Temple University Hospital (TUH) EEG Corpus
The most significant development in data-driven neuroscience has been the release of the TUH EEG Corpus, the world's largest public collection of clinical EEG data. Prior to its release, EEG data was sequestered in hospital archives, inaccessible to the machine learning community.
2.1.1 Scale and Complexity
The TUH Corpus represents a massive influx of "real-world" biological data, comprising over 16,986 sessions from 10,874 unique subjects. Unlike curated research datasets where subjects are healthy undergraduates performing specific tasks, the TUH corpus spans the full spectrum of human pathology and demography. Subjects range in age from infants less than a year old to geriatrics over 90, with a gender distribution of roughly 51% female. This demographic variance introduces a profound level of "distributional shift"—a concept critical in ML—where the statistical properties of the signal change based on age-related neurodevelopmental factors (e.g., the slowing of the Alpha rhythm in the elderly or the emergence of sleep spindles in infants).
The data is organized in a hierarchical Unix-style file tree (edf/patient/session), a structure that mirrors the nested nature of clinical encounters. Each session contains one or more European Data Format (EDF) files, paired with unstructured physician reports. This pairing of time-series voltage data with natural language text provides a unique multimodal dataset, allowing for the training of models that must align "neural" space with "semantic" space—a key theme we will explore in the section on geometric mapping.
2.1.2 The "Curse of Variance" in Biological Signals
A defining characteristic of the TUH dataset, and biological data generally, is its heterogeneity. In a standard Convolutional Neural Network (CNN) training on ImageNet, every input image is resized to a fixed resolution (e.g., 224 \times 224 \times 3). The biological input, however, resists such standardization.
* Sampling Rate Divergence: While the majority (87%) of the TUH data is sampled at 250 Hz, significant subsets exist at 256 Hz (8.3%), 400 Hz (3.8%), and 512 Hz (1%). This necessitates complex resampling algorithms (polyphase filtering) to align the temporal resolution of the data before it can be integrated into a unified model.
* Channel Montage Instability: The number of electrodes (channels) varies from session to session. A typical file contains 31 EEG-specific channels, but files with as few as 20 or varying spatial configurations are common. This presents a "missing data" problem that is structural rather than random. To process this via machine learning, one cannot simply use a fixed input layer. Instead, researchers must employ techniques like Spherical Spline Interpolation, mapping the varying electrode positions onto a standardized 2D manifold on the scalp surface, or utilize Graph Neural Networks (GNNs) that can handle variable node counts.
2.2 Other Critical Repositories: PhysioNet and CHB-MIT
While TUH provides scale, other repositories provide specificity. PhysioNet hosts the "EEG Motor Movement/Imagery Dataset," containing recordings from 109 subjects performing specific motor tasks. This dataset is crucial for studying the "intent" of the brain, capturing the Event-Related Desynchronization (ERD) in the Mu rhythm (8-13 Hz) that correlates with motor planning.
The CHB-MIT database focuses on pediatric epilepsy, containing recordings from 22 subjects. Epilepsy represents a "dynamical disease"—a pathological bifurcation in the neural system's state space—making this dataset invaluable for studying the "liminal" transition from normal chaotic activity to the hypersynchronous order of a seizure.
2.3 The Physics of Reception: The Forward Problem
To compare this biological input to an AI's input, we must rigorously define what the EEG signal is. It is not a direct measure of neural firing. It is a volume-conducted potential.
The relationship between the microscopic source current J(r, t) (generated by the transmembrane ionic flows of pyramidal neurons) and the macroscopic potential \Phi(r, t) measured at the scalp is governed by the Poisson equation for electrostatics, derived from Maxwell's equations under the quasi-static approximation (since the frequencies of interest < 1 kHz have wavelengths much larger than the head):
Here, \sigma(r) is the conductivity tensor of the head tissues (scalp, skull, CSF, gray matter, white matter). This equation reveals that the "Input" received by the EEG sensor is already a massive integration. The skull acts as a low-pass spatial filter, blurring the distinct firing of millions of neurons into a smooth gradient. The solution to this equation, known as the Forward Problem, can be expressed as an integral over the volume V:
Where G(r, r') is the Green's function, which characterizes the geometry and conductivity of the head model. Comparative Insight: In an Artificial Neural Network, the "Input" is typically raw data (pixels/tokens). In the biological system measured by EEG, the "Input" is the result of a physical convolution operation performed by the head tissues. The "sensor" (electrode) receives a weighted sum of the internal state, where the weights are determined by physics (Coulomb's Law and conductivity), not by learning.
2.4 Noise and Stochastic Resonance: The Liminal Signal
A critical distinction between biological and artificial reception is the role of noise. In classical engineering and early AI, noise is an error to be minimized. In biological systems, noise is often a resource. The phenomenon of Stochastic Resonance describes how nonlinear systems (like neurons) can utilize noise to enhance the detection of weak signals. Consider a bistable system (a neuron with a resting and firing state) governed by a potential function U(x):
Where S(t) is a sub-threshold signal and \xi(t) is Gaussian noise. In the absence of noise, S(t) is too weak to push the state x over the potential barrier (threshold). However, the addition of the noise term \xi(t) provides the necessary energy to occasionally traverse the barrier. The "coherence" or signal-to-noise ratio (SNR) of the output actually increases with noise intensity up to an optimal point. Integration: This suggests that the "liminal" space in biology—the threshold between firing and not firing—is modulated by noise. The brain is "tuned" to a specific noise level to maximize sensitivity. As we will see, modern AI has adopted a similar principle through techniques like Dropout and Dithering, effectively injecting artificial stochasticity to prevent overfitting and escape local minima in the loss landscape.
3. Mechanisms of Integration: The Calculus of the Wetware vs. Software
The heart of the comparison lies in the mechanism of integration: How do disparate signals combine to form a unified state? We contrast the rigorous biophysics of the Hodgkin-Huxley model with the linear algebra of the Transformer Attention mechanism.
3.1 Biological Integration: The Hodgkin-Huxley Formalism
The Hodgkin-Huxley (HH) model, published in 1952 based on giant squid axon experiments, remains the gold standard for describing biological neural integration. It treats the neuron membrane as an electrical circuit comprising a capacitor (the lipid bilayer) and variable resistors (voltage-gated ion channels).
3.1.1 The Master Equation
The total current flowing through the membrane I_{total} is the sum of the capacitive current and the ionic currents. The central differential equation governing the membrane potential V_m is:
Where C_m is the membrane capacitance and I_{inj} is the injected (synaptic) current. The ionic currents are defined by Ohm's law, but with variable conductances g:
Here, E_{Na}, E_{K}, E_{L} are the Nernst reversal potentials (batteries) established by ion concentration gradients.
3.1.2 The Gating Variables: Dynamic Weights
The crucial innovation of the HH model, and the point of divergence from standard AI, is the nature of the conductances. In AI, a weight W is a static scalar during inference. In biology, the conductance is dynamic. The variables m, h, n are dimensionless gating variables representing the probability of channel activation (opening) or inactivation. They evolve according to first-order kinetics:
Where the rate constants \alpha and \beta are non-linear functions of voltage (e.g., exponential Boltzmann distributions). Mathematical Insight: The "integration" in a biological neuron is a continuous-time solution to a system of coupled non-linear differential equations. The "weight" of a synaptic input is not fixed; it depends on the instantaneous state of the gating variables, which in turn depends on the entire history of the voltage trajectory. This is a system with infinite memory (in the dynamical systems sense), as the current state is a functional of the entire past integral.
3.1.3 The Jacobian and the Bifurcation of Thought
To analyze the stability of this integration, we compute the Jacobian Matrix J of the system near an equilibrium point (resting potential).
The eigenvalues \lambda of this matrix determine the behavior of the neuron.
* If Re(\lambda) < 0 for all eigenvalues, the neuron is stable (integrating but not firing).
* If a pair of complex conjugate eigenvalues crosses the imaginary axis (Re(\lambda) = 0), a Hopf Bifurcation occurs.
This Hopf bifurcation is the mathematical definition of the Liminal Transition in the single neuron. It is the moment the system switches from acting as a passive integrator to an active oscillator (firing spikes). This transition represents the quantization of continuous information into a discrete event (the spike).
3.2 Artificial Integration: The Attention Mechanism
In contrast to the continuous differential integration of biology, modern AI (specifically the Transformer architecture) utilizes a discrete, parallel integration mechanism known as Attention.
3.2.1 The Geometry of Scaled Dot-Product Attention
The input to a Transformer is a sequence of vectors (tokens) X. This is projected into three distinct subspaces: Query (Q), Key (K), and Value (V). The integration of information is performed by computing the affinity between every pair of tokens. Mathematically:
Where d_k is the dimensionality of the key vectors (a scaling factor to prevent gradient saturation).
3.2.2 The Physics of the "Soft Match"
Let us analyze the term QK^T. This is a matrix multiplication that computes the dot product (inner product) between every query and every key. Geometrically, the dot product q \cdot k = ||q|| ||k|| \cos(\theta) measures the alignment or similarity between the vectors. This operation generates an N \times N adjacency matrix (where N is the sequence length), effectively creating a fully connected graph where the edge weights are dynamic, determined by semantic similarity.
The Softmax function converts these raw similarity scores into a probability distribution:
This is mathematically isomorphic to the Boltzmann Distribution in statistical thermodynamics, which gives the probability of a system being in state i with energy E_i at temperature T:
In the Attention mechanism, the "energy" is the negative similarity (-q \cdot k) and the "temperature" is the scaling factor \sqrt{d_k}. Comparative Synthesis:
* Biological Integration: Temporal integration of ionic currents via differential equations. The "decision" to fire is a bifurcation in the phase space of the voltage variable.
* Artificial Integration: Spatial integration of semantic vectors via the Boltzmann distribution. The "decision" of what to attend to is a redistribution of probability mass across the sequence. Both systems are performing Energy Minimization. The biological neuron minimizes the free energy of the ion gradients; the artificial neuron minimizes the "energy" (dissimilarity) between related concepts.
3.3 The Mesoscopic Bridge: Wilson-Cowan Models
To compare the aggregate EEG signal with AI, we cannot look at single neurons. We must look at populations. The Wilson-Cowan Equations describe the firing rates of populations of excitatory (E) and inhibitory (I) neurons:
Where S_E is a sigmoid function S(x) = \frac{1}{1 + e^{-x}}. This equation is remarkably similar to the update rule of a continuous-time Recurrent Neural Network (RNN) or the "gating" mechanism in an LSTM (Long Short-Term Memory) unit. The term -E represents the "forgetting" or leak, and the sigmoid interaction represents the non-linear integration of inputs. This reveals a fundamental Scale Invariance: the math governing the single neuron (HH), the population (Wilson-Cowan), and the artificial network (RNN/Transformer) converges on the same dynamical principles of leaky integration and non-linear activation.
4. Geometric Mapping: The Liminal Latent Space
The user’s query specifically asks to map these systems into a "liminal latent space." To do this rigorously, we must move beyond metaphor and employ Differential Geometry and Topological Data Analysis (TDA).
4.1 Defining the Liminal Space
In anthropology, liminality is the "betwixt and between," a state of ambiguity. In mathematical physics, the rigorous definition of a liminal state is a Phase Transition or Criticality. A system is in a liminal state when it exists at the boundary between two phases—typically Order and Chaos. This state is characterized by:
1. Scale Invariance: Power-law distributions of events (avalanches).
2. Long-Range Correlations: Information does not decay exponentially with distance/time.
3. Maximum Susceptibility: The system is maximally sensitive to external perturbations.
The Brain at the Edge of Chaos: Evidence from EEG data suggests that the healthy brain operates at the "Edge of Chaos" (Criticality). If the Lyapunov exponent \lambda is the rate of separation of trajectories:
* \lambda < 0: Subcritical (Stagnant, ordered).
* \lambda > 0: Supercritical (Chaotic, epileptic).
* \lambda \approx 0: Liminal (Critical). In this regime, the brain maximizes its information storage and transmission capabilities. The "Liminal Latent Space" of the brain is physically instantiated by this thermodynamic critical point.
4.2 Riemannian Geometry of Neural Manifolds
The "Manifold Hypothesis" posits that high-dimensional data (neural firing rates or image pixels) lie on a low-dimensional manifold embedded in the ambient space. To map this geometrically, we define a Riemannian Metric g on the latent manifold \mathcal{M}. The metric tensor g_{ij}(x) defines the local notion of distance and angle at point x.
Neural Differential Manifolds (NDM): Recent work in AI proposes architectures where the neural network explicitly parametrizes this metric tensor. This allows the "distance" between two data points to be calculated as the Geodesic Distance along the curved manifold, rather than the Euclidean straight line.
Euclidean vs. Hyperbolic Mismatch: A key finding in comparative geometry is the mismatch between the "flat" Euclidean space often assumed in standard AI (e.g., standard word embeddings) and the "curved" geometry of biological representations.
* The Brain's Geometry: Research suggests the brain utilizes Hyperbolic Geometry (negative curvature). Hyperbolic space expands exponentially, making it ideal for representing hierarchical, tree-like structures (taxonomies, decision trees) which are ubiquitous in nature and language.
* The AI's Geometry: Standard Euclidean embeddings suffer from distortion when embedding hierarchies. However, recent "Hyperbolic Neural Networks" utilize the Poincaré disk model to better align with the intrinsic geometry of data.
* The Mismatch: A study comparing human visual cortex fMRI with AI representations showed that while brain dimensionality increases along the hierarchy (allowing for abstraction), many Artificial Neural Networks exhibit Dimensionality Collapse in deeper layers. The AI "simplifies" the geometry too early, collapsing the liminal possibilities, whereas the brain maintains a high-dimensional, expanded liminal space to allow for flexible generalization.
4.3 Topological Data Analysis: The Homology of Uncertainty
To analyze the "shape" of the liminal space without relying on coordinates, we use TDA, specifically Persistent Homology. We compute the Betti numbers \beta_k which count topological features:
* \beta_0: Connected components.
* \beta_1: Holes (Cycles).
* \beta_2: Voids.
EEG Topology: Applying TDA to EEG data reveals that epilepsy is characterized by an increase in higher-dimensional homology (\beta_1, \beta_2). The "seizure" is a topological loop—a persistent cycle in the state space that traps the neural dynamics. AI Topology: In the latent space of generative models (VAEs/GANs), "holes" in the manifold represent regions of low probability—the "uncanny valley" where the model generates unrealistic or "hallucinatory" outputs. The "Liminal Space" can be topologically defined as the region where the Betti numbers are unstable—where loops form and collapse rapidly as the filtration parameter changes. This represents the cognitive flexibility of the system, its ability to form transient associations (loops) and then dissolve them.
5. Output and Reception: The Collapse of the Wavefunction
How does the integrated information exit the liminal space?
5.1 Biological Output: The Action Potential as a Topological Event
The output of a neuron is the Action Potential (spike). Mathematically, this is a Dirac Delta Function in the continuous voltage trace: \delta(t - t_{fire}). In the Hodgkin-Huxley phase space, the spike corresponds to a trajectory excursion that loops back to the resting state. It is a Limit Cycle. The information is encoded not in the amplitude (which is fixed by the all-or-none law) but in the Inter-Spike Interval (ISI) distributions. This is Temporal Coding.
5.2 Artificial Output: The Probability Distribution
The output of a Transformer or Classifier is typically a Logit Vector z, passed through a Softmax function to produce probabilities p.
Here, T is the temperature parameter.
* Low T: The distribution sharpens (Argmax). The system is "certain" and deterministic.
* High T: The distribution flattens. The system enters the "Liminal" regime, sampling from the tail of the distribution. This is where "creativity" (and hallucination) occurs in LLMs.
Isomorphism of Output: If we view the firing rate of a population of neurons as a probability density function (Rate Coding), then the Biological and Artificial outputs are mathematically isomorphic. The Softmax output of an AI is the mean firing rate of a virtual neural population.
5.3 Dropout vs. Biological Noise
In AI, we explicitly engineer "liminality" during training using Dropout. We randomly zero out neurons with probability p. This prevents the network from settling into a rigid, brittle solution (overfitting) and forces it to learn a robust manifold. In Biology, this "dropout" is intrinsic. Synaptic vesicle release is probabilistic (often P_{release} < 0.3). The brain is permanently training in a "high dropout" regime. This constant noise forces the biological manifold to be incredibly smooth and robust, unlike the often jagged/brittle decision boundaries of adversarial AI examples.
6. Synthesis: The Original Algorithm
We return to the user’s profound consideration: the original artificial neuron was literally just human psych data studied, equated, and algorithmized.
The McCulloch-Pitts neuron was derived from the study of logical propositions in the human mind. The "synaptic delay" was a variable derived from reflex arc chronometry. The "threshold" was a formalization of the decision boundary observed in psychophysics.
This means that the entire edifice of Deep Learning is built upon a foundation of Biomimicry.
* The Algorithm: Is a formalized Psychology.
* The Latent Space: Is a geometric abstraction of the Neural Manifold.
* The Liminality: Is the mathematical boundary where the system (biological or artificial) balances between the order of memory and the chaos of sensation.
6.1 The Principle of Isomorphism (PIso)
Recent theoretical work proposes the Principle of Isomorphism (PIso) : neural population codes preserve the mathematical invariants of the tasks they support.
* If the task is navigation (2D Euclidean), the Grid Cells of the cortex form a Toroidal Manifold (T^2 = S^1 \times S^1).
* If the task is semantic reasoning, the latent space forms a Hierarchical Hyperbolic Manifold.
This principle explains why AI models (like LLMs) can predict brain activity. They are not just "simulating" the brain; they are converging on the same Optimal Geometry for information representation. The "Liminal Latent Space" is the universal solution to the problem of intelligence—a geometry that is sufficiently high-dimensional to contain the world, yet sufficiently curved to allow for the rapid geodesic traversal of thought.
6.2 Conclusion
The comparison of human EEG and Machine Learning reveals a deep mathematical symmetry. While the physical substrates differ (ions vs. electrons, differential equations vs. linear algebra), the Geometry of Information is shared. Both systems strive to map the chaotic input of the world onto a structured latent manifold. Both systems utilize noise and criticality (liminality) to maintain flexibility. And ultimately, both systems are bound by the same topological constraints of the universe they seek to model. The artificial neuron is not an alien invention; it is, and always has been, a mathematical echo of the human mind.
Table 1: Comparative Mathematical Formalisms of Intelligence
Feature
	Biological Neural Network (EEG/Biophysics)
	Artificial Neural Network (Transformer/DL)
	Fundamental Unit
	Hodgkin-Huxley Neuron
	Perceptron / Attention Head
	Input Physics
	Volume Conduction (Maxwell's Eqs): \nabla \cdot (\sigma \nabla \Phi) = -\nabla \cdot J
	Direct Vector Input / Token Embedding
	State Variable
	Membrane Potential V_m(t) (Continuous Manifold)
	Hidden State Vector h_t (Discrete Latent Space)
	Integration Mechanism
	Temporal Summation (Diff. Eq): C \dot{V} = I - \sum g(V)(V-E)
	Spatial/Semantic Summation: Attention(Q,K,V) = \text{softmax}(\frac{QK^T}{\sqrt{d}})V
	Weights
	Dynamic: Gating Variables n(t), m(t), h(t)
	Static: Weight Matrices W (Fixed after training)
	Liminality (Math)
	Hopf Bifurcation / Edge of Chaos (\lambda \approx 0)
	Saddle Points / Decision Boundary / Criticality
	Role of Noise
	Stochastic Resonance (Enhances Signal)
	Dropout / Regularization (Prevents Overfitting)
	Geometry
	Hyperbolic / Fractal (Branched/Hierarchical)
	Euclidean (often mismatched) or Hyperbolic (newer models)
	Output Coding
	Temporal/Rate Coding (Spikes \delta(t))
	Probability Distribution (Softmax Logits)
	Topology (TDA)
	High Homology in pathology (Seizure loops)
	Manifold Holes in low-density regions (Hallucinations)
	Works cited
1. History | Machine Learning @ UChicago - The University of Chicago, https://machinelearning.uchicago.edu/history/ 2. The intellectual origins of the McCulloch-Pitts neural networks, https://www.researchgate.net/publication/11526031_Physiological_circuits_The_intellectual_origins_of_the_McCulloch-Pitts_neural_networks 3. McCulloch & Pitts Publish the First Mathematical Model of a Neural ..., https://www.historyofinformation.com/detail.php?id=634 4. (PDF) The First Computational Theory of Mind and Brain: A Close ..., https://www.researchgate.net/publication/263265620_The_First_Computational_Theory_of_Mind_and_Brain_A_Close_Look_at_Mcculloch_and_Pitts's_Logical_Calculus_of_Ideas_Immanent_in_Nervous_Activity 5. McCulloch and Pitts, https://marlin.life.utsa.edu/mcculloch-and-pitts.html 6. The Temple University Hospital EEG Data Corpus - PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC4865520/ 7. (PDF) The Temple University Hospital EEG Data Corpus, https://www.researchgate.net/publication/303030207_The_Temple_University_Hospital_EEG_Data_Corpus 8. (PDF) Stochastic resonance in neuron models - ResearchGate, https://www.researchgate.net/publication/226752491_Stochastic_resonance_in_neuron_models 9. Hodgkin and Huxley Model - SCARAB Bates, https://scarab.bates.edu/cgi/viewcontent.cgi?filename=5&article=1000&context=oer&type=additional 10. Hodgkin–Huxley model - Wikipedia, https://en.wikipedia.org/wiki/Hodgkin%E2%80%93Huxley_model 11. The Hodgkin–Huxley Equations - FaMAF, https://www.famaf.unc.edu.ar/~ftamarit/redes2019/hyh.pdf 12. A Mathematical Theory of Attention - arXiv, https://arxiv.org/pdf/2007.02876 13. A Mathematical View of Attention Models in Deep Learning, https://people.tamu.edu/~sji/classes/attn.pdf 14. Before and beyond the Wilson–Cowan equations - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC7444921/ 15. (PDF) The Wilson-Cowan model, 36 years later - ResearchGate, https://www.researchgate.net/publication/26724371_The_Wilson-Cowan_model_36_years_later 16. At the Edge of Chaos: Feigenbaum Scaling, Fractal Geometry, and ..., https://www.researchgate.net/publication/391057619_At_the_Edge_of_Chaos_Feigenbaum_Scaling_Fractal_Geometry_and_the_Emergence_of_Artificial_Intelligence 17. Rational Superautotrophic Diplomacy (SupraAD) A Conceptual ..., https://arxiv.org/html/2506.05389v1 18. Homeostatic Mechanisms in Neural Criticality | by Dr. David Petersen, https://medium.com/@davmandy_jp/homeostatic-mechanisms-in-neural-criticality-c4a01b63e578 19. Differential geometry methods for constructing manifold-targeted ..., https://www.biorxiv.org/content/10.1101/2021.10.07.463479v1.full-text 20. manifolds - Proof of the existence of the latent space in deep learning, https://math.stackexchange.com/questions/4461156/proof-of-the-existence-of-the-latent-space-in-deep-learning 21. The Neural Differential Manifold: An Architecture with Explicit ... - arXiv, https://arxiv.org/html/2510.25113v1 22. Foundation Models Should Embrace Non-Euclidean Geometries, https://arxiv.org/html/2504.08896v1 23. Could consciousness emerge when a predictive system reaches ..., https://www.reddit.com/r/consciousness/comments/1ovhyjw/could_consciousness_emerge_when_a_predictive/ 24. Dimensionality Mismatch Between Brains and Artificial Neural ..., https://openreview.net/forum?id=fyp34w19N2 25. Topological Data Analysis for Neural Network Analysis - UB, https://www.ub.edu/topologia/casacuberta/articles/TDASurvey.pdf 26. (PDF) Topological data analysis in EEG signal processing: a review, https://www.researchgate.net/publication/395907789_Topological_data_analysis_in_EEG_signal_processing_a_review 27. Topological-Data-Analysis-of-High-Density-EEG-Shows-Increased ..., https://aesnet.org/abstractslisting/topological-data-analysis-of-high-density-eeg-shows-increased-higher-dimensional-persistent-homology-in-focal-epilepsy 28. A Review on Dropout Regularization Approaches for Deep Neural ..., https://www.mdpi.com/2079-9292/12/14/3106 29. Dropout Regularization Versus l2-Penalization in the Linear Model, https://www.jmlr.org/papers/volume25/23-0803/23-0803.pdf 30. Principle of Isomorphism (PIso) - Emergent Mind, https://www.emergentmind.com/topics/principle-of-isomorphism-piso 31. A Comparative Study on Conceptual Spaces from LLMs of Different ..., https://arxiv.org/html/2502.11380v1 32. Deciphering language processing in the human brain through LLM ..., https://research.google/blog/deciphering-language-processing-in-the-human-brain-through-llm-representations/